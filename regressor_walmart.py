# -*- coding: utf-8 -*-
"""Atividade3-Regressor-Walmart.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mA08Iv5RSO2ubDXMHVv-D47OWIwxapjQ

UNIVERSIDADE FEDERAL DE ALFENAS
> TRABALHO DE INTELIGENCIA ARTIFICIAL


> Componentes:

*   Bárbara Silveira Rodrigues - 2021.1.08.042
*   Renan Magalhães Lage - 2021.1.08.020
"""

#Configurando o drive
from google.colab import drive
drive.mount('/content/drive')

#Obtendo os dados do arquivo
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import pandas as pd
import matplotlib.pyplot as plt
import datetime
import seaborn as sns
import numpy as np
import sklearn
sns.set()
url_dataset= "/content/drive/MyDrive/IA/Walmart.csv"
data = pd.read_csv(url_dataset)
data.head()

data.info()

#Transformando os dados
data['Date'] = pd.to_datetime(data['Date'])
#Gerando um gráfico Vendas Semanais sobre o tempo
plt.figure(figsize=(20,5))

sns.lineplot(x=data.Date, y=(data.Weekly_Sales/1e6))

plt.xlabel('Months')
plt.ylabel('Weekly Sales (in million USD)')
plt.title('Weekly Sales Trend', fontdict={'fontsize': 17, 'color':'red'}, pad=20)

plt.show()

data['Day'] = data['Date'].dt.weekday
data['Week'] = data['Date'].dt.week
data['Month'] = data['Date'].dt.month
data['Year']  = data['Date'].dt.year
data.drop('Date',axis=1,inplace=True)
data.head()

# Exibindo  dimensao da base de dados
print("Dimensão dos dados:")
print("Linhas (Instâncias):{}".format(data.shape[0]))
print("Colunas (Atributos):{}".format(data.shape[1]))

#Verificando dados nulos
data.isnull().sum()

# Separando os dados em features e target
features = data.drop('Weekly_Sales', axis=1)
target = data['Weekly_Sales']

# Aplicando a funcao train_test_split para dividir o conjunto original em 70% para treindo e 30% para teste
features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.3, random_state=1)

print('Tamanho Features Treinamento: ', len(features_train))
print('Tamanho Features Teste: ', len(features_test))
print('Tamanho Target Treinamento: ', len(target_train))
print('Tamanho Target Teste: ', len(target_test))

with open('treinamento.txt', 'w+') as f:


      for items in target_test:
          f.write('%s\n' %items)

      print("File written successfully")


f.close()

#Como precisamos de dividir o modelo de treinamento em 4 partes vamos fazer divisões por dois sucessivas para obter isso
features_um, features_dois, target_um, target_dois= train_test_split(features_train, target_train, test_size=0.5, random_state=1)
print('Tamanho features 1: ',len(features_um))
print('Tamanho features 2: ',len(features_dois))
print('Tamanho saida 1: ',len(target_um))
print('Tamanho saida 2: ',len(target_dois))

#Agora iremos dividir os dois grupos obtidos na iteração passada por dois, obtendo quatro grupos diferentes
features_um, features_tres, target_um, target_tres= train_test_split(features_um,target_um, test_size=0.5, random_state=123)
features_dois, features_quatro, target_dois, target_quatro= train_test_split(features_dois, target_dois, test_size=0.5, random_state=1)
print('Tamanho features 1: ',len(features_um))
print('Tamanho features 2: ',len(features_tres))
print('Tamanho features 3: ',len(features_dois))
print('Tamanho features 4: ',len(features_quatro))
print('-----------------------')
print('Tamanho target 1: ',len(target_um))
print('Tamanho target 2: ',len(target_tres))
print('Tamanho target 3: ',len(target_dois))
print('Tamanho target 4: ',len(target_quatro))

"""# K-NEAREST NEIGBOURS - KNN"""

from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, classification_report

from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import GridSearchCV
# Definir parâmetros para busca em grade, esses parametros serao variados para atingir o objetivo pedido no trabalho (Devem ser geradas 15 variações de parâmetros para cada uma das 4 tecnicas de IA;)
parameters = {
    'n_neighbors': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]
}

# Lista para armazenar os resultados dos modelos, vamos armazenar os melhores
resultados = []

# Armazenando cada conjunto em uma array para fazer o loop
subconjuntos_features = [features_um, features_dois, features_tres, features_quatro]
subconjuntos_target = [target_um, target_dois, target_tres, target_quatro]

# Loop pelos subconjuntos de treinamento
for i in range(len(subconjuntos_features)):
    X_train = subconjuntos_features[i]
    y_train = subconjuntos_target[i]

    # Criar o classificador de árvore de decisão
    classificador = KNeighborsRegressor(metric='euclidean')

    # Realizar busca em grade para encontrar a melhor combinação de parametros
    buscaGrade = GridSearchCV(classificador, parameters, scoring='neg_mean_absolute_percentage_error', cv=5)
    buscaGrade.fit(X_train, y_train)

    # Obter os melhores parametros encontrados e a melhor pontuação
    melhorParam = buscaGrade.best_params_
    melhorPont = buscaGrade.best_score_

    # Armazenar os resultados
    resultados.append((melhorParam, melhorPont))

# Exibir os resultados
for i in range(len(resultados)):
    print(f"Resultados para subconjunto de treinamento {i+1}:")
    print("Melhores parâmetros:", resultados[i][0])
    print("Melhor pontuação:", resultados[i][1]*-1)
    print()

"""## Testando o KNN"""

import matplotlib.pyplot as plt
import numpy
from sklearn import metrics
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_absolute_percentage_error

# Loop pelos subconjuntos de teste
predicao_KNN= [[] for i in range(4)]
for i in range(4):

    # Criar o classificador de arvore de decisao com os melhores parametros encontrados
    classifier = KNeighborsRegressor(**resultados[i][0])

    # Treinar o classificador com o conjunto de treinamento correspondente
    classifier.fit(subconjuntos_features[i], subconjuntos_target[i])

    # Fazer previsoes no conjunto de teste
    y_pred = classifier.predict(features_test)
    predicao_KNN[i] = y_pred

    # Calcular todas as metricas
    r2 = r2_score(target_test, y_pred,)
    MSE = mean_squared_error(target_test,y_pred)
    RMSE = mean_squared_error(target_test,y_pred, squared=False)
    MAE = mean_absolute_error(target_test,y_pred)
    MAPE = mean_absolute_percentage_error(target_test, y_pred)

    # Exibicao dos resultados
    print(f"-----Subsconjundo de dados {i+1}-----")
    print(f"R2 para o Teste : {r2}")
    #print(f"Erro Quadrático Médio para o Teste : {MSE}")
    #print(f"Raiz Erro Quadrático Médio para o Teste : {RMSE}")
    print(f"Erro Absoluto Médio para o Teste : {MAE}")
    print(f"Mean Absolute Percentage Error para o Teste : {MAPE}")
    print()

for i in range(4):
  print(f"Lista de Resultados do Teste {i+1}")
  print()
  print(predicao_KNN[i])
  print()

for i in range(4):
  with open(f'KNN_{i+1}.txt', 'w+') as f:


      for items in predicao_KNN[i]:
          f.write('%s\n' %items)

      print("File written successfully")


  f.close()

"""# FLORESTA ALEATÓRIA

O código de floresta aleatória demora alguns minutos para rodar
"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
# Definir parâmetros para busca em grade, esses parametros serao variados para atingir o objetivo pedido no trabalho (Devem ser geradas 15 variações de parâmetros para cada uma das 4 tecnicas de IA;)
parameters = {
    'n_estimators': [300,310,320,330,340],
    'max_depth': [5, 10, 15]
}

# Lista para armazenar os resultados dos modelos, vamos armazenar os melhores
resultados = []

# Armazenando cada conjunto em uma array para fazer o loop
subconjuntos_features = [features_um, features_dois, features_tres, features_quatro]
subconjuntos_target = [target_um, target_dois, target_tres, target_quatro]

# Loop pelos subconjuntos de treinamento
for i in range(len(subconjuntos_features)):
    X_train = subconjuntos_features[i]
    y_train = subconjuntos_target[i]

    # Criar o classificador de árvore de decisão
    classificador = RandomForestRegressor(n_jobs=-1)

    # Realizar busca em grade para encontrar a melhor combinação de parametros
    buscaGrade = GridSearchCV(classificador, parameters, scoring='neg_mean_absolute_percentage_error', cv=5)
    buscaGrade.fit(X_train, y_train)

    # Obter os melhores parametros encontrados e a melhor pontuação
    melhorParam = buscaGrade.best_params_
    melhorPont = buscaGrade.best_score_

    # Armazenar os resultados
    resultados.append((melhorParam, melhorPont))

# Exibir os resultados
for i in range(len(resultados)):
    print(f"Resultados para subconjunto de treinamento {i+1}:")
    print("Melhores parâmetros:", resultados[i][0])
    print("Melhor pontuação:", resultados[i][1]*-1)
    print()

"""## Testando a Floresta Aleatória"""

import matplotlib.pyplot as plt
import numpy
from sklearn import metrics
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_absolute_percentage_error

# Loop pelos subconjuntos de teste
predicao_Floresta= [[] for i in range(4)]
for i in range(4):

    # Criar o classificador de arvore de decisao com os melhores parametros encontrados
    classifier = RandomForestRegressor(**resultados[i][0])

    # Treinar o classificador com o conjunto de treinamento correspondente
    classifier.fit(subconjuntos_features[i], subconjuntos_target[i])

    # Fazer previsoes no conjunto de teste
    y_pred = classifier.predict(features_test)
    predicao_Floresta[i] = y_pred

    # Calcular todas as metricas
    r2 = r2_score(target_test, y_pred,)
    MSE = mean_squared_error(target_test,y_pred)
    RMSE = mean_squared_error(target_test,y_pred, squared=False)
    MAE = mean_absolute_error(target_test,y_pred)
    MAPE = mean_absolute_percentage_error(target_test, y_pred)

    # Exibicao dos resultados
    print(f"-----Subsconjundo de dados {i+1}-----")
    print(f"R2 para o Teste : {r2}")
    #print(f"Erro Quadrático Médio para o Teste : {MSE}")
    #print(f"Raiz Erro Quadrático Médio para o Teste : {RMSE}")
    print(f"Erro Absoluto Médio para o Teste : {MAE}")
    print(f"Mean Absolute Percentage Error para o Teste : {MAPE}")
    print()

for i in range(4):
  print(f"Lista de Resultados do Teste {i+1}")
  print()
  print(predicao_Floresta[i])
  print()

for i in range(4):
  with open(f'Floresta_{i+1}.txt', 'w+') as f:


      for items in predicao_Floresta[i]:
          f.write('%s\n' %items)

      print("File written successfully")


  f.close()

"""# Árvore de Decisão

Estrutura na qual cada nó interno representa um "teste" em um atributo do banco de dados
"""

# Importando bibliotecas
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import GridSearchCV

# Definir parametros para a busca em grade
parameters = {
    'max_depth': [5, 10, 15, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Lista para armazenar os resultados dos modelos, vamos armazenar os melhores
resultados = []

# Armazenando cada conjunto em uma array para fazer o loop
subconjuntos_features = [features_um, features_dois, features_tres, features_quatro]
subconjuntos_target = [target_um, target_dois, target_tres, target_quatro]

# Loop pelos subconjuntos de treinamento
for i in range(len(subconjuntos_features)):
    X_train = subconjuntos_features[i]
    y_train = subconjuntos_target[i]

    # Criar o classificador de árvore de decisão
    regressor = DecisionTreeRegressor()

    # Realizar busca em grade para encontrar a melhor combinação de parametros
    buscaGrade = GridSearchCV(regressor, parameters, scoring='neg_mean_absolute_percentage_error', cv=5)
    buscaGrade.fit(X_train, y_train)

    # Obter os melhores parametros encontrados e a melhor pontuação
    melhorParam = buscaGrade.best_params_
    melhorPont = buscaGrade.best_score_

    # Armazenar os resultados
    resultados.append((melhorParam, melhorPont))

# Exibir os resultados
for i in range(len(resultados)):
    print(f"Resultados para subconjunto de treinamento {i+1}:")
    print("Melhores parâmetros:", resultados[i][0])
    print("Melhor pontuação:", resultados[i][1]*(-1))
    print()

"""## Testando a Árvore de Decisão"""

# Importando bibliotecas
from sklearn.tree import DecisionTreeRegressor
import matplotlib.pyplot as plt
import numpy as np
from sklearn import metrics
import matplotlib.pyplot as plt
import numpy
from sklearn import metrics
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_absolute_percentage_error

# Loop pelos subconjuntos de teste
predicao_arvore= [[] for i in range(4)]
for i in range(4):

    # Criar o classificador de arvore de decisao com os melhores parametros encontrados
    classificador = DecisionTreeRegressor(**resultados[i][0])

    # Treinar o classificador com o conjunto de treinamento correspondente
    classificador.fit(subconjuntos_features[i], subconjuntos_target[i])

    # Fazer previsoes no conjunto de teste
    y_pred = classificador.predict(features_test)
    predicao_arvore[i] = y_pred

    # Calcular todas as metricas
    r2 = r2_score(target_test, y_pred,)
    MSE = mean_squared_error(target_test,y_pred)
    RMSE = mean_squared_error(target_test,y_pred, squared=False)
    MAE = mean_absolute_error(target_test,y_pred)
    MAPE = mean_absolute_percentage_error(target_test, y_pred)

    # Exibicao dos resultados
    print(f"-----Subsconjundo de dados {i+1}-----")
    print(f"R2 para o Teste : {r2}")
    print(f"Erro Absoluto Médio para o Teste : {MAE}")
    print(f"Mean Absolute Percentage Error para o Teste : {MAPE}")
    print()

for i in range(4):
  print(f"Lista de Resultados do Teste {i+1}")
  print()
  print(predicao_arvore[i])
  print()

for i in range(4):
  with open(f'Arvore_{i+1}.txt', 'w+') as f:


      for items in predicao_arvore[i]:
          f.write('%s\n' %items)

      print("File written successfully")


  f.close()

"""# XGBoost

Faz um "ensemble" com as árvores de decisão para o treinamento
"""

# Importando bibliotecas
from sklearn.model_selection import GridSearchCV
import xgboost as xgb
from xgboost import XGBRegressor

# Definir parametros para a busca em grade
param_grid = {
    'max_depth': [3, 5],
    'learning_rate': [0.1, 0.05],
    'n_estimators': [100, 200]
}

# Lista para armazenar os resultados dos modelos, vamos armazenar os melhores
resultados = []

# Armazenando cada conjunto em uma array para fazer o loop
subconjuntos_features = [features_um, features_dois, features_tres, features_quatro]
subconjuntos_target = [target_um, target_dois, target_tres, target_quatro]

# Loop pelos subconjuntos de treinamento
for i in range(len(subconjuntos_features)):
    X_train = subconjuntos_features[i]
    y_train = subconjuntos_target[i]

    # Realizar busca em grade para encontrar a melhor combinação de parametros
    buscaGrade = GridSearchCV(XGBRegressor(), param_grid, cv=3)
    buscaGrade.fit(X_train, y_train)

    # Obter os melhores parametros encontrados e a melhor pontuação
    melhorParam = buscaGrade.best_params_
    melhorPont = buscaGrade.best_score_

    model = XGBRegressor(**melhorParam)
    model.fit(X_train, y_train)

    # Armazenar os resultados
    resultados.append((melhorParam, melhorPont))

# Exibir os resultados
for i in range(len(resultados)):
    print(f"Resultados para subconjunto de treinamento {i+1}:")
    print("Melhores parâmetros:", resultados[i][0])
    print("Melhor pontuação:", resultados[i][1])
    print()

"""## Testando o XGBoost"""

# Importando bibliotecas
from sklearn.tree import DecisionTreeRegressor
import matplotlib.pyplot as plt
import numpy as np
from sklearn import metrics

# Loop pelos subconjuntos de teste
predicao_xgboost= [[] for i in range(4)]
for i in range(4):

    # Criar o classificador de árvore de decisão com os melhores parâmetros encontrados
    classificador = XGBRegressor(**resultados[i][0])

    # Treinar o classificador com o conjunto de treinamento correspondente
    classificador.fit(subconjuntos_features[i], subconjuntos_target[i])

    # Fazer previsões no conjunto de teste
    y_pred = classificador.predict(features_test)
    predicao_xgboost[i] = y_pred

   # Calcular todas as metricas
    r2 = r2_score(target_test, y_pred,)
    MSE = mean_squared_error(target_test,y_pred)
    RMSE = mean_squared_error(target_test,y_pred, squared=False)
    MAE = mean_absolute_error(target_test,y_pred)
    MAPE = mean_absolute_percentage_error(target_test, y_pred)

    # Exibicao dos resultados
    print(f"-----Subsconjundo de dados {i+1}-----")
    print(f"R2 para o Teste : {r2}")
    print(f"Erro Absoluto Médio para o Teste : {MAE}")
    print(f"Mean Absolute Percentage Error para o Teste : {MAPE}")
    print()

for i in range(4):
  print(f"Lista de Resultados do Teste {i+1}")
  print()
  print(predicao_xgboost[i])
  print()

for i in range(4):
  with open(f'XGBoost_{i+1}.txt', 'w+') as f:


      for items in predicao_xgboost[i]:
          f.write('%s\n' %items)

      print("File written successfully")


  f.close()