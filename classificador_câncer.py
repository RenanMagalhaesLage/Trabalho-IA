# -*- coding: utf-8 -*-
"""Atividade3-Classificador-Câncer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pHC_CC8VbJj3SonfSGKkPcT5pPsb-Wge

UNIVERSIDADE FEDERAL DE ALFENAS
> TRABALHO DE INTELIGENCIA ARTIFICIAL


> Componentes:

*   Bárbara Rodrigues Silveira - 2021.1.08.042
*   Renan Magalhães Lage - 2021.1.08.020
"""

#Configurando o drive
from google.colab import drive
drive.mount('/content/drive')

# Importanto as bibliotecas
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
#--------------------------------------------------
# Processamento dos dados
#--------------------------------------------------
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
#--------------------------------------------------

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

data = pd.read_csv("/content/drive/MyDrive/IA/breast-cancer-wisconsin.csv")

data.head()

# Exibindo  dimensao da base de dados
print("Dimensão dos dados:")
print("Linhas (Instâncias):{}".format(data.shape[0]))
print("Colunas (Atributos):{}".format(data.shape[1]))

#Verificando dados nulos
data.isnull().sum()

# Distribuicao das instancias
B, M = data['diagnosis'].value_counts()
print('Benignos : ',B)
print('Malignos : ',M)
print('---------------------')
print('Proporção de Benignos: ', 100*B/(B+M))
print('Proporção de Malignos: ', 100*M/(B+M))

# Separando os dados em entrada e saida desejada e removendo as colunas 'diagnosis' e 'id'
dadosEntrada = data.drop(['diagnosis','id'], axis=1)
saidaDesejada = data['diagnosis']

# Aplicando a função LabelEncoder na variavel saidaDesejada
saidaDesejada = LabelEncoder().fit_transform(saidaDesejada)

# Aplicando a funcao train_test_split para dividir o conjunto original em 70% para treindo e 30% para teste
dadosEntrada_train, dadosEntrada_test, saidaDesejada_train, saidaDesejada_test = train_test_split(dadosEntrada, saidaDesejada, test_size=0.3, random_state=1)

print('Tamanho Dados de Entrada Treinamento: ', len(dadosEntrada_train))
print('Tamanho Dados de Entrada Teste: ', len(dadosEntrada_test))
print('Tamanho Saída Desejada Treinamento: ', len(saidaDesejada_train))
print('Tamanho Saída Desejada Teste: ', len(saidaDesejada_test))

saidaDesejada_test

"""Dividindo os dados de treino em quatro partes

"""

#Como precisamos de dividir o modelo de treinamento em 4 partes vamos fazer divisões por dois sucessivas para obter isso
treino_um, treino_dois, saida_um, saida_dois= train_test_split(dadosEntrada_train, saidaDesejada_train, test_size=0.5, random_state=1)
print('Tamanho treino 1: ',len(treino_um))
print('Tamanho treino 2: ',len(treino_dois))
print('Tamanho saida 1: ',len(saida_um))
print('Tamanho saida 2: ',len(saida_dois))

#Agora iremos dividir os dois grupos obtidos na iteração passada por dois, obtendo quatro grupos diferentes
treino_um, treino_tres, saida_um, saida_tres= train_test_split(treino_um,saida_um, test_size=0.5, random_state=1)
treino_dois, treino_quatro, saida_dois, saida_quatro= train_test_split(treino_dois, saida_dois, test_size=0.5, random_state=1)
print('Tamanho treino 1: ',len(treino_um))
print('Tamanho treino 2: ',len(treino_tres))
print('Tamanho treino 3: ',len(treino_dois))
print('Tamanho treino 4: ',len(treino_quatro))
print('-----------------------')
print('Tamanho saida 1: ',len(saida_um))
print('Tamanho saida 2: ',len(saida_tres))
print('Tamanho saida 3: ',len(saida_dois))
print('Tamanho saida 4: ',len(saida_quatro))

"""# K-NEAREST NEIGBOURS - KNN


"""

# Carregando o modelo inteligente e as metricas de desempenho
#------------------------------------------------------------
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, classification_report,fbeta_score

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer
# Definir parâmetros para busca em grade, esses parametros serao variados para atingir o objetivo pedido no trabalho (Devem ser geradas 15 variações de parâmetros para cada uma das 4 tecnicas de IA;)
parameters = {
    'n_neighbors': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17],
    'metric': ['euclidean']
}
meus_scores = {'accuracy' :make_scorer(accuracy_score),
               'recall'   :make_scorer(recall_score),
               'precision':make_scorer(precision_score),
               'f1'       :make_scorer(f1_score)}

# Lista para armazenar os resultados dos modelos, vamos armazenar os melhores
resultados = []

# Armazenando cada conjunto em uma array para fazer o loop
subconjuntos_treinamento = [treino_um, treino_dois, treino_tres, treino_quatro]
subconjuntos_saida = [saida_um, saida_dois, saida_tres, saida_quatro]

# Loop pelos subconjuntos de treinamento
for i in range(len(subconjuntos_treinamento)):
    X_train = subconjuntos_treinamento[i]
    y_train = subconjuntos_saida[i]

    # Criar o classificador de árvore de decisão
    classificador = KNeighborsClassifier()

    # Realizar busca em grade para encontrar a melhor combinação de parametros
    buscaGrade = GridSearchCV(classificador, parameters, scoring = meus_scores, refit = 'recall', cv=5)
    buscaGrade.fit(X_train, y_train)

    # Obter os melhores parametros encontrados e a melhor pontuação
    melhorParam = buscaGrade.best_params_
    melhorPont = buscaGrade.best_score_

    # Armazenar os resultados
    resultados.append((melhorParam, melhorPont))

# Exibir os resultados
for i in range(len(resultados)):
    print(f"Resultados para subconjunto de treinamento {i+1}:")
    print("Melhores parâmetros:", resultados[i][0])
    print("Melhor pontuação:", resultados[i][1])
    print()

"""# Testando o KNN"""

import matplotlib.pyplot as plt
import numpy
from sklearn import metrics

# Loop pelos subconjuntos de teste
predicao_KNN= [[] for i in range(4)]
for i in range(4):

    # Criar o classificador de arvore de decisao com os melhores parametros encontrados
    classifier = KNeighborsClassifier(**resultados[i][0])

    # Treinar o classificador com o conjunto de treinamento correspondente
    classifier.fit(subconjuntos_treinamento[i], subconjuntos_saida[i])

    # Fazer previsoes no conjunto de teste
    y_pred = classifier.predict(dadosEntrada_test)
    predicao_KNN[i] = y_pred

    # Calcular todas as metricas
    accuracy = accuracy_score(saidaDesejada_test, y_pred)
    precision = precision_score(saidaDesejada_test, y_pred)
    recall = recall_score(saidaDesejada_test, y_pred)  # Calcula a recall
    f1 = f1_score(saidaDesejada_test, y_pred)  # Calcula o F1 score

    # Exibicao dos resultados
    print(f"-----Subsconjundo de dados {i+1}-----")
    print(f"Acuracia para o Teste : {accuracy}")
    print(f"Precision para o Teste : {precision}")
    print(f"Recall para o Teste : {recall}")
    print(f"F1 Score para o Teste : {f1}")
    print("\n")
    print(f"-----Matriz de Confusão {i+1}-----")

    confusion_matrix = metrics.confusion_matrix(saidaDesejada_test,  y_pred)

    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])

    cm_display.plot()
    plt.show()

for i in range(4):
  print(f"Lista de Resultados do Teste {i+1}")
  print()
  print(predicao_KNN[i])
  print()

"""# FLORESTA ALEATÓRIA"""

# Carregando o modelo inteligente e as metricas de desempenho
#------------------------------------------------------------
from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from math import sqrt
from sklearn import metrics

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer
# Definir parâmetros para busca em grade, esses parametros serao variados para atingir o objetivo pedido no trabalho (Devem ser geradas 15 variações de parâmetros para cada uma das 4 tecnicas de IA;)
parameters = {
    'n_estimators': [200],
    'max_depth': [5, 10, 15,20,25,30,35,40,45,50,55,60,65,70,75]
}
meus_scores = {'accuracy' :make_scorer(accuracy_score),
               'recall'   :make_scorer(recall_score),
               'precision':make_scorer(precision_score),
               'f1'       :make_scorer(f1_score)}
# Lista para armazenar os resultados dos modelos, vamos armazenar os melhores
resultados = []

# Armazenando cada conjunto em uma array para fazer o loop
subconjuntos_treinamento = [treino_um, treino_dois, treino_tres, treino_quatro]
subconjuntos_saida = [saida_um, saida_dois, saida_tres, saida_quatro]

# Loop pelos subconjuntos de treinamento
for i in range(len(subconjuntos_treinamento)):
    X_train = subconjuntos_treinamento[i]
    y_train = subconjuntos_saida[i]

    # Criar o classificador de árvore de decisão
    classificador = RandomForestClassifier(n_jobs=-1)

    # Realizar busca em grade para encontrar a melhor combinação de parametros
    buscaGrade = GridSearchCV(classificador, parameters, scoring=meus_scores, refit = 'recall', cv=5)
    buscaGrade.fit(X_train, y_train)

    # Obter os melhores parametros encontrados e a melhor pontuação
    melhorParam = buscaGrade.best_params_
    melhorPont = buscaGrade.best_score_

    # Armazenar os resultados
    resultados.append((melhorParam, melhorPont))

# Exibir os resultados
for i in range(len(resultados)):
    print(f"Resultados para subconjunto de treinamento {i+1}:")
    print("Melhores parâmetros:", resultados[i][0])
    print("Melhor pontuação:", resultados[i][1])
    print()

"""# Testando a Floresta Aleatória"""

import matplotlib.pyplot as plt
import numpy
from sklearn import metrics

# Loop pelos subconjuntos de teste
predicao_Floresta= [[] for i in range(4)]
for i in range(4):

    # Criar o classificador de arvore de decisao com os melhores parametros encontrados
    classifier = RandomForestClassifier(**resultados[i][0])

    # Treinar o classificador com o conjunto de treinamento correspondente
    classifier.fit(subconjuntos_treinamento[i], subconjuntos_saida[i])

    # Fazer previsoes no conjunto de teste
    y_pred = classifier.predict(dadosEntrada_test)
    predicao_Floresta[i] = y_pred

  # Calcular todas as metricas
    accuracy = accuracy_score(saidaDesejada_test, y_pred)
    precision = precision_score(saidaDesejada_test, y_pred)
    recall = recall_score(saidaDesejada_test, y_pred)  # Calcula a recall
    f1 = f1_score(saidaDesejada_test, y_pred)  # Calcula o F1 score

    # Exibicao dos resultados
    print(f"-----Subsconjundo de dados {i+1}-----")
    print(f"Acuracia para o Teste : {accuracy}")
    print(f"Precision para o Teste : {precision}")
    print(f"Recall para o Teste : {recall}")
    print(f"F1 Score para o Teste : {f1}")
    print("\n")
    print(f"-----Matriz de Confusão {i+1}-----")

    confusion_matrix = metrics.confusion_matrix(saidaDesejada_test,  y_pred)

    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])

    cm_display.plot()
    plt.show()

for i in range(4):
  print(f"Lista de Resultados do Teste {i+1}")
  print()
  print(predicao_Floresta[i])
  print()

"""# Árvore de Decisão"""

# Importando bibliotecas
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

# Definir parâmetros para busca em grade, esses parametros serao variados para atingir o objetivo pedido no trabalho (Devem ser geradas 15 variações de parâmetros para cada uma das 4 tecnicas de IA;)
parameters = {
    'criterion': ['gini', 'entropy'], # Gini mede a impureza de um no com base na probabilidade de classificacao incorreta e entropy a impureza com base na informacao
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 5]
}

# Lista para armazenar os resultados dos modelos, vamos armazenar os melhores
resultados = []

# Armazenando cada conjunto em uma array para fazer o loop
subconjuntos_treinamento = [treino_um, treino_dois, treino_tres, treino_quatro]
subconjuntos_saida = [saida_um, saida_dois, saida_tres, saida_quatro]

# Loop pelos subconjuntos de treinamento
for i in range(len(subconjuntos_treinamento)):
    X_train = subconjuntos_treinamento[i]
    y_train = subconjuntos_saida[i]

    # Criar o classificador de árvore de decisão
    classificador = DecisionTreeClassifier()

    # Realizar busca em grade para encontrar a melhor combinação de parametros
    buscaGrade = GridSearchCV(classificador, parameters, scoring='accuracy', cv=5)
    buscaGrade.fit(X_train, y_train)

    # Obter os melhores parametros encontrados e a melhor pontuação
    melhorParam = buscaGrade.best_params_
    melhorPont = buscaGrade.best_score_

    # Armazenar os resultados
    resultados.append((melhorParam, melhorPont))

# Exibir os resultados
for i in range(len(resultados)):
    print(f"Resultados para subconjunto de treinamento {i+1}:")
    print("Melhores parâmetros:", resultados[i][0])
    print("Melhor pontuação:", resultados[i][1])
    print()

"""# Testando a árvore de Decisão"""

# Importando bibliotecas
from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix, classification_report

# Criando subconjuntos para os testes
subconjuntos_teste = [dadosEntrada_test, dadosEntrada_test, dadosEntrada_test, dadosEntrada_test]
subconjuntos_saida_teste = [saidaDesejada_test, saidaDesejada_test, saidaDesejada_test, saidaDesejada_test]

predicao_arvore= [[] for i in range(4)]
# Loop pelos subconjuntos de teste
for i in range(len(subconjuntos_teste)):
    X_test = subconjuntos_teste[i]
    y_test = subconjuntos_saida_teste[i]

    # Criar o classificador de arvore de decisao com os melhores parametros encontrados
    classifier = DecisionTreeClassifier(**resultados[i][0])

    # Treinar o classificador com o conjunto de treinamento correspondente
    classifier.fit(subconjuntos_treinamento[i], subconjuntos_saida[i])

    # Fazer previsoes no conjunto de teste
    y_pred = classifier.predict(X_test)
    predicao_arvore[i] = y_pred

    # Calcular todas as metricas
    accuracy = accuracy_score(saidaDesejada_test, y_pred)
    accuracy = accuracy_score(saidaDesejada_test, y_pred)
    recall = recall_score(saidaDesejada_test, y_pred)  # Calcula a recall
    f1 = f1_score(saidaDesejada_test, y_pred) # Calcula o F1 score

    # Exibicao dos resultados
    print(f"Previsao para o subconjunto de teste {i+1}: {y_pred}")
    print(f"Acuracia para subconjunto de teste {i+1}: {accuracy}")
    print(f"Recall para subconjunto de teste {i+1}: {recall}")
    print(f"F1 Score para subconjunto de teste {i+1}: {f1}")
    print("Matriz de Confusao:")
    print(classification_report(y_test, y_pred)) # plotando o relatório (de cima)
    print()

for i in range(4):
  print(f"Lista de Resultados do Teste {i+1}")
  print()
  print(predicao_arvore[i])
  print()

"""# XGBOOST"""

# Importando bibliotecas
from sklearn.model_selection import GridSearchCV
from xgboost.sklearn import XGBClassifier


# Armazenando cada conjunto em uma array para fazer o loop
subconjuntos_treinamento = [treino_um, treino_dois, treino_tres, treino_quatro]
subconjuntos_saida = [saida_um, saida_dois, saida_tres, saida_quatro]

# Parametros pra a busca em grade
param_grid = {
    'max_depth': [3, 5],
    'learning_rate': [0.1, 0.05],
    'n_estimators': [100, 200]
}

# Array para armazenar os resultados
resultados = []

for i in range(len(subconjuntos_treinamento)):
    X_train = subconjuntos_treinamento[i]
    y_train = subconjuntos_saida[i]

    print(f"Subconjunto {i+1}")
    # Realiza a busca pelos melhores parametros
    # Cria o objeto do GridSearchCV para a busca em grade utilizando um classificador XGBoost
    buscaGrade = GridSearchCV(XGBClassifier(), param_grid, cv=3)
    buscaGrade.fit(X_train, y_train)

    # Obtem os melhores parametros encontrados
    melhorParam = buscaGrade.best_params_
    melhorPont = buscaGrade.best_score_

    # Treina o modelo com os melhores parametros encontrados
    model = XGBClassifier(**melhorParam)
    model.fit(X_train, y_train)

    # Armazena o resultado
    resultado = (melhorParam, melhorPont)
    resultados.append(resultado)

    # Exibindo resultados
    print("Resultado para subconjunto de treinamento:")
    print("Melhores parâmetros encontrados:", melhorParam)
    print("Melhores pontuação encontrados:", melhorPont)
    print()

"""# Testando XGBOOST"""

# Importando bibliotecas
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

# Criando subconjuntos para os testes
subconjuntos_teste = [dadosEntrada_test, dadosEntrada_test, dadosEntrada_test, dadosEntrada_test]
subconjuntos_saida_teste = [saidaDesejada_test, saidaDesejada_test, saidaDesejada_test, saidaDesejada_test]

# Loop pelos subconjuntos de teste
for i in range(len(subconjuntos_teste)):
    X_test = subconjuntos_teste[i]
    y_test = subconjuntos_saida_teste[i]

    # Criar o classificador de arvore de decisao com os melhores parametros encontrados
    classifier = XGBClassifier(**resultados[i][0])

    # Treinar o classificador com o conjunto de treinamento correspondente
    classifier.fit(subconjuntos_treinamento[i], subconjuntos_saida[i])

    # Fazer previsoes no conjunto de teste
    y_pred = classifier.predict(X_test)

    # Calcular todas as metricas
    accuracy = accuracy_score(saidaDesejada_test, y_pred)
    precision = precision_score(saidaDesejada_test, y_pred)
    recall = recall_score(saidaDesejada_test, y_pred)  # Calcula a recall
    f1 = f1_score(saidaDesejada_test, y_pred)  # Calcula o F1 score

    # Exibicao dos resultados
    print(f"Previsao para o subconjunto de teste {i+1}: {y_pred}")
    print(f"Acuracia para subconjunto de teste {i+1}: {accuracy}")
    print(f"Precisao para o subconjunto de teste {i+1}: {precision}")
    print(f"Recall para subconjunto de teste {i+1}: {recall}")
    print(f"F1 Score para subconjunto de teste {i+1}: {f1}")
    print("Matriz de Confusao:")
    print(classification_report(y_test, y_pred)) # plotando o relatório (de cima)
    print()